# -*- coding: utf-8 -*-
"""Fake_Accounts_Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BfteZDqgFL97MMNLQ9VXegZnWMVyyV9J

#df_1, Fake accounts prediction

##imoorting libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing,model_selection,linear_model,metrics,svm
from mlxtend.plotting import plot_confusion_matrix
import xgboost as xgb
from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re
import string
from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer

"""##load CSV dataset"""

df_1 = pd.read_csv("/content/all_users_proccessed.csv")
df_1

df_1.shape

df_1.isnull().sum()

df_1.info()

sns.countplot(x='label', data=df_1)

"""##save manual test dataset"""

df_testing = df_1.copy()

df_testing.drop(columns='label',axis=0,inplace=True)

df_testing

df_fake = df_testing.tail(1)
for i in range(4154,4153,-1):
  df_testing.drop([i],axis=0,inplace=True)

df_fake.to_csv("fake_testing.csv")

df_true = df_testing.head(1)
for i in range(1,0,-1):
  df_testing.drop([i],axis=0,inplace=True)

df_true.to_csv("true_testing.csv")

"""##WordNetLemmatizer"""

df_1['description'].head(10)

nltk.download("stopwords")

df_1['lang'].value_counts()

stop_words1 = set(stopwords.words(['italian','english','spanish','french','german','dutch','turkish']))
print(stop_words1)

wordnet = WordNetLemmatizer()

def prepare_description(x):
  x = x.lower()
  x = ' '.join([word for word in x.split(' ') if word not in stop_words1])
  x = x.encode('utf-8').decode()
  x = re.sub(r'https*\S+',' ',x)
  x = re.sub(r'@\S+',' ',x)
  x = re.sub(r'#\S+',' ',x)
  x = re.sub(r'\'\w+',' ',x)
  x = re.sub('[%s]' % re.escape(string.punctuation),' ',x)
  x = re.sub(r'\w*\d+\w*',' ',x)
  x = re.sub(r'\s{2,}',' ',x)
  return x

df_1['description'] = df_1['description'].apply(prepare_description)
df_1

df_1.info()

"""##merging the data"""

df_1['content'] = str(df_1['statuses_count'])+' '+str(df_1['followers_count'])+' '+str(df_1['friends_count'])+' '+str(df_1['favourites_count'])+' '+str(df_1['listed_count'])+' '+df_1['lang']+' '+df_1['time_zone']+' '+str(df_1['geo_enabled'])+' '+df_1['profile_use_background_image']+' '+df_1['profile_text_color']+' '+df_1['profile_sidebar_border_color']+' '+df_1['profile_background_tile']+' '+df_1['profile_sidebar_fill_color']+' '+df_1['profile_background_color']+' '+df_1['profile_link_color']+' '+df_1['utc_offset']+' '+df_1['description']
df_1['content']

"""##vector"""

vector = TfidfVectorizer(stop_words=stop_words1,lowercase=False)
vector

df_tf = vector.fit_transform(df_1['content'])
df_tf

"""##x,y"""

x1 = df_tf
x1

y1 = df_1['label'].values
y1

"""##Test algorithms accuracy's score(before fitting)"""

models = []
models.append(("LR",linear_model.LogisticRegression()))
models.append(("XGB",xgb.XGBClassifier()))
models.append(("Grand",GradientBoostingClassifier()))
models.append(("SVM",svm.SVC()))
models.append(("Forest",RandomForestClassifier()))

results = []
names = []
scoring = 'accuracy'

for name,model in models:
  kfold = model_selection.KFold(n_splits=10)
  cv_results = model_selection.cross_val_score(model,x1,y1,cv=kfold,scoring=scoring)
  results.append(cv_results)
  names.append(name)
  msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
  print(msg)

fig = plt.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()

"""##split dataset into train and test"""

x1_train,x1_test,y1_train,y1_test = model_selection.train_test_split(
    x1,y1,
    test_size=0.3,
    random_state=42,
    shuffle=True,
    stratify=y1
)

x1_train.shape,x1_test.shape,y1_train.shape,y1_test.shape

"""##Logistic regression """

logistic_model_1 = linear_model.LogisticRegression()
logistic_model_1.fit(x1_train,y1_train)

log_pred1_train = logistic_model_1.predict(x1_train)
log_pred1_test = logistic_model_1.predict(x1_test)

print(f'Training Score: \n{metrics.classification_report(y1_train,log_pred1_train)}')

print(f'Testing Score: \n{metrics.classification_report(y1_test,log_pred1_test)}')

confusion_matrix=metrics.confusion_matrix(y1_test,log_pred1_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.bone_r,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##XGBoost"""

xgb_model_1 = xgb.XGBClassifier()
xgb_model_1.fit(x1_train,y1_train)

xgb_pred1_train = xgb_model_1.predict(x1_train)
xgb_pred1_test = xgb_model_1.predict(x1_test)

print(f'Training Score: \n{metrics.classification_report(y1_train,xgb_pred1_train)}')

print(f'Testing Score: \n{metrics.classification_report(y1_test,xgb_pred1_test)}')

confusion_matrix=metrics.confusion_matrix(y1_test,xgb_pred1_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.bone_r,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##Gradient Boosting"""

grad_model_1 = GradientBoostingClassifier()
grad_model_1.fit(x1_train,y1_train)

grad_pred1_train = grad_model_1.predict(x1_train)
grad_pred1_test = grad_model_1.predict(x1_test)

print(f'Training Score: \n{metrics.classification_report(y1_train,grad_pred1_train)}')

print(f'Testing Score: \n{metrics.classification_report(y1_test,grad_pred1_test)}')

confusion_matrix=metrics.confusion_matrix(y1_test,grad_pred1_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.bone_r,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##SVM"""

svm_model_1 = svm.SVC()
svm_model_1.fit(x1_train,y1_train)

svm_pred1_train = svm_model_1.predict(x1_train)
svm_pred1_test = svm_model_1.predict(x1_test)

print(f'Training Score: \n{metrics.classification_report(y1_train,svm_pred1_train)}')

print(f'Testing Score: \n{metrics.classification_report(y1_test,svm_pred1_test)}')

confusion_matrix=metrics.confusion_matrix(y1_test,svm_pred1_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.bone_r,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##Random Forest"""

forest_1 = RandomForestClassifier()
forest_1.fit(x1_train,y1_train)

forest_pred1_train = forest_1.predict(x1_train)
forest_pred1_test = forest_1.predict(x1_test)

print(f'Training Score: \n{metrics.classification_report(y1_train,forest_pred1_train)}')

print(f'Testing Score: \n{metrics.classification_report(y1_test,forest_pred1_test)}')

confusion_matrix=metrics.confusion_matrix(y1_test,forest_pred1_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.bone_r,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##Testing new data """

def output_label(n):
  if n == 0:
    return "Fake Acoount"
  elif n ==1:
    return "Not Fake Account"

def Prediction(statuses_count,followers_count,friends_count,
               favourites_count,listed_count,lang,
               time_zone,geo_enabled,profile_use_background_image,
               profile_text_color,profile_sidebar_border_color,
               profile_background_tile,profile_sidebar_fill_color,
               profile_background_color,profile_link_color,
               utc_offset,description):


  a = {"statuses_count":[statuses_count]} 
  new_a = pd.DataFrame(a)
  new_a_test = new_a["statuses_count"]

  b = {"followers_count":[followers_count]}
  new_b = pd.DataFrame(b)
  new_b_test = new_b["followers_count"]

  c = {"friends_count":[friends_count]}
  new_c = pd.DataFrame(c)
  new_c_test = new_c["friends_count"]

  d = {"favourites_count":[favourites_count]}
  new_d = pd.DataFrame(d)
  new_d_test = new_d["favourites_count"]

  e = {"listed_count":[listed_count]}
  new_e = pd.DataFrame(e)
  new_e_test = new_e["listed_count"]

  f = {"lang":[lang]}
  new_f = pd.DataFrame(f)
  new_f_test = new_f["lang"]

  g = {"time_zone":[time_zone]}
  new_g = pd.DataFrame(g)
  new_g_test = new_g["time_zone"]

  h = {"geo_enabled":[geo_enabled]}
  new_h = pd.DataFrame(h)
  new_h_test = new_h["geo_enabled"]

  i = {"profile_use_background_image":[profile_use_background_image]}
  new_i = pd.DataFrame(i)
  new_i_test = new_i["profile_use_background_image"]

  j = {"profile_text_color":[profile_text_color]}
  new_j = pd.DataFrame(j)
  new_j_test = new_j["profile_text_color"]

  k = {"profile_sidebar_border_color":[profile_sidebar_border_color]}
  new_k = pd.DataFrame(k)
  new_k_test = new_k["profile_sidebar_border_color"]

  l = {"profile_background_tile":[profile_background_tile]}
  new_l = pd.DataFrame(l)
  new_l_test = new_l["profile_background_tile"]

  m = {"profile_sidebar_fill_color":[profile_sidebar_fill_color]}
  new_m = pd.DataFrame(m)
  new_m_test = new_m["profile_sidebar_fill_color"]

  n = {"profile_background_color":[profile_background_color]}
  new_n = pd.DataFrame(n)
  new_n_test = new_n["profile_background_color"]

  o = {"profile_link_color":[profile_link_color]}
  new_o = pd.DataFrame(o)
  new_o_test = new_o["profile_link_color"]

  p = {"utc_offset":[utc_offset]}
  new_p = pd.DataFrame(p)
  new_p_test = new_p["utc_offset"]

  q = {"description":[description]}
  new_q = pd.DataFrame(q)
  new_q["description"] = new_q["description"].apply(prepare_description)
  new_q_test = new_q["description"]

  new_alldf = new_a_test+' '+new_b_test+' '+new_c_test+' '+new_d_test+' '+new_e_test+' '+new_f_test+' '+new_g_test+' '+new_h_test+' '+new_i_test+' '+new_j_test+' '+new_k_test+' '+new_l_test+' '+new_m_test+' '+new_n_test+' '+new_o_test+' '+new_p_test+' '+new_q_test
  new_vector = vector.transform(new_alldf)

  grad_pred1_test = grad_model_1.predict(new_vector)

  return print("\n\nPrediction: {}".format(
      output_label(grad_pred1_test)
  ))

statuses_count = str(input())
followers_count = str(input())
friends_count = str(input())
favourites_count = str(input())
listed_count = str(input())
lang = str(input())
time_zone = str(input())
geo_enabled = str(input())
profile_use_background_image = str(input())
profile_text_color = str(input())
profile_sidebar_border_color = str(input())
profile_background_tile = str(input())
profile_sidebar_fill_color = str(input())
profile_background_color = str(input())
profile_link_color = str(input())
utc_offset = str(input())
description = str(input())


Prediction(statuses_count,followers_count,friends_count,
               favourites_count,listed_count,lang,
               time_zone,geo_enabled,profile_use_background_image,
               profile_text_color,profile_sidebar_border_color,
               profile_background_tile,profile_sidebar_fill_color,
               profile_background_color,profile_link_color,
               utc_offset,description)

"""##joblib, Saving best model"""

from joblib import dump

dump(grad_model_1,"grad_model.joblib")
dump(vector,"vector.joblib")