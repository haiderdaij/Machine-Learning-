# -*- coding: utf-8 -*-
"""Sensitive_Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yYhtdqvhVM6Wr7OKq9zggirjTmzkFv1x

#df_2

##imporing libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import preprocessing,model_selection,linear_model,metrics,svm,neighbors,tree
from mlxtend.plotting import plot_confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re
import string

"""##load csv dataset"""

df_2 = pd.read_csv("/content/text classification.csv",encoding='latin-1')
df_2

df_2.shape

df_2.isnull().sum()

df_2.info()

df_2['twitte'].head(10)

"""##Frac = 1"""

df_2.sample(frac=1)

"""##show the relationship between class and twitte"""

sns.set(font_scale=1.4)
df_2['class'].value_counts().plot(kind='bar', figsize=(7, 6), rot=0)
plt.xlabel("class", labelpad=14)
plt.ylabel("twitte", labelpad=14)

"""##WordNetLemmatizer"""

nltk.download("stopwords")

stop_words2 = set(stopwords.words('english'))
print(stop_words2)

wordnet = WordNetLemmatizer()

def prepare_twitte(x):
  x = x.lower()
  x = ' '.join([word for word in x.split(' ') if word not in stop_words2])
  x = x.encode('utf-8').decode()
  x = re.sub(r'https*\S+',' ',x) # URL http
  x = re.sub(r'www.\S+',' ',x) #www.blablaaa
  x = re.sub(r'@\S+',' ',x) # mention 
  x = re.sub(r'#\S+',' ',x) # hashtag 
  x = re.sub(r"\'\w+"," ",x) # stop_words2
  x = re.sub("[%s]" % re.escape(string.punctuation)," ",x) #punctuations
  x = re.sub(r"\w*\d+\w*"," ",x)
  x = re.sub(r"\s{2,}"," ",x)
  return x

df_2['clean_twitte'] = df_2['twitte'].apply(prepare_twitte)
df_2

df_2['clean_twitte'].tail(30)

"""##convert class to be (0,1)"""

not_sensitive_label,sensitive_label = (0,1)

df_2['class'] = df_2['class'].map({
    'not sensitive': not_sensitive_label,
    'sensitive': sensitive_label
})

df_2['class'].value_counts()

"""##Vectorizer"""

vectorization = TfidfVectorizer(stop_words=stop_words2)

df_twitte = vectorization.fit_transform(df_2['clean_twitte'])

"""##x , y"""

x2 = df_twitte
x2

y2 = df_2['class'].values
y2

"""##Test algorithms accuracy's score(before fitting)"""

models = []
models.append(("LR",linear_model.LogisticRegression()))
models.append(("SVM",svm.SVC()))
models.append(("Forest",RandomForestClassifier()))
models.append(("KNN",neighbors.KNeighborsClassifier()))
models.append(("Tree",tree.DecisionTreeClassifier()))

results = []
names = []
scoring = 'accuracy'

for name, model in models:
  kfold = model_selection.KFold(n_splits=10)
  cv_results = model_selection.cross_val_score(model,x2,y2,cv=kfold,scoring=scoring)
  results.append(cv_results)
  names.append(name)
  msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
  print(msg)

"""##split dataset into train and test"""

x2_train,x2_test,y2_train,y2_test = model_selection.train_test_split(
    x2,y2,
    test_size=0.25,
    random_state=42,
    shuffle=True,
    stratify=y2)

x2_train.shape,x2_test.shape,y2_train.shape,y2_test.shape

"""##Logistic regression """

logistic_model_2 = linear_model.LogisticRegressionCV()
logistic_model_2.fit(x2_train,y2_train)

log_pred2_train = logistic_model_2.predict(x2_train)
log_pred2_test = logistic_model_2.predict(x2_test)

print(f'Training Score: \n{metrics.classification_report(y2_train,log_pred2_train)}')

print(f'Testing Score: \n{metrics.classification_report(y2_test,log_pred2_test)}')

confusion_matrix=metrics.confusion_matrix(y2_test,log_pred2_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.Blues,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##SVM"""

svm_model_2 = svm.SVC()
svm_model_2.fit(x2_train,y2_train)

svm_pred2_train = svm_model_2.predict(x2_train)
svm_pred2_test = svm_model_2.predict(x2_test)

print(f'Training Score: \n{metrics.classification_report(y2_train,svm_pred2_train)}')

print(f'Testing Score: \n{metrics.classification_report(y2_test,svm_pred2_test)}')

confusion_matrix=metrics.confusion_matrix(y2_test,svm_pred2_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.Blues,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##Random Forest"""

forest_model_2 = RandomForestClassifier()
forest_model_2.fit(x2_train,y2_train)

forest_pred2_train = forest_model_2.predict(x2_train)
forest_pred2_test = forest_model_2.predict(x2_test)

print(f'Training Score: \n{metrics.classification_report(y2_train,forest_pred2_train)}')

print(f'Testing Score: \n{metrics.classification_report(y2_test,forest_pred2_test)}')

confusion_matrix=metrics.confusion_matrix(y2_test,forest_pred2_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.Blues,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##KNN"""

knn_model_2 = neighbors.KNeighborsClassifier()
knn_model_2.fit(x2_train,y2_train)

knn_pred2_train = knn_model_2.predict(x2_train)
knn_pred2_test = knn_model_2.predict(x2_test)

print(f'Training Score: \n{metrics.classification_report(y2_train,knn_pred2_train)}')

print(f'Testing Score: \n{metrics.classification_report(y2_test,knn_pred2_test)}')

confusion_matrix=metrics.confusion_matrix(y2_test,knn_pred2_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.Blues,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##Tree"""

tree_model_2 = tree.DecisionTreeClassifier()
tree_model_2.fit(x2_train,y2_train)

tree_pred2_train = tree_model_2.predict(x2_train)
tree_pred2_test = tree_model_2.predict(x2_test)

print(f'Training Score: \n{metrics.classification_report(y2_train,tree_pred2_train)}')

print(f'Testing Score: \n{metrics.classification_report(y2_test,tree_pred2_test)}')

confusion_matrix=metrics.confusion_matrix(y2_test,tree_pred2_test)
fig= plot_confusion_matrix(conf_mat=confusion_matrix,cmap=plt.cm.Blues,figsize=(10,10))
plt.xlabel('Prediction',fontsize=16)
plt.ylabel('Actual',fontsize=16)
plt.title('Confusion Matrix',fontsize=16)
plt.show()

"""##best model?

**Random Forest** is the best model so i will take it to testing on new data.

##predict new dataset
"""

def output_label_2(n):
  if n == 0:
    return "Not Sensitive"
  elif n == 1:
    return "Sensitive"

def test_2(news):
  testing_news_2 = {'twitte':[news]}
  news_def_2 = pd.DataFrame(testing_news_2)
  news_def_2['clean_twitte'] = news_def_2['twitte'].apply(prepare_twitte)
  news_x2_test = news_def_2['clean_twitte']
  news_xv2_test = vectorization.transform(news_x2_test)

  forest_pred2_test = forest_model_2.predict(news_xv2_test)

  return print("\n\nPrediction: {}".format(output_label_2(forest_pred2_test)))

news = str(input())
test_2(news)

"""##joblib"""

from joblib import dump

dump(forest_model_2,"model_2.joblib")
dump(vectorization,"vector_2.joblib")